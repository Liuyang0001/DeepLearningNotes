{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算图\n",
    "\n",
    "计算图通过节点和箭头表示计算过程。节点用○表示，○中是计算的内容。将计算的中间结果写在箭头的上方，表示各个节点的计算结果从左向右传递。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题1： 太郎在超市买了2 个100 日元一个的苹果，消费税是10%，请计算支付金额。\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200801203004.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题2：  太郎在超市买了2 个苹果、3 个橘子。其中，苹果每个100 日元，橘子每个150 日元。消费税是10%，请计算支付金额。\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200801203111.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用计算图解题的情况下，需要按如下流程进行。\n",
    "\n",
    "1. 构建计算图。\n",
    "\n",
    "2. 在计算图上，从左向右进行计算。\n",
    "\n",
    "这里的第2 歩“从左向右进行计算”是一种正方向上的传播，简称为正向传播（forward propagation）。正向传播是从计算图出发点到结束点的传播。既然有正向传播这个名称，当然也可以考虑反向（从图上看的话，就是从右向左）的传播。实际上，这种传播称为反向传播（backward propagation）。反向传播将在接下来的导数计算中发挥重要作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 链式求导法则\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200801233353.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 反向传播是基于链式法则的\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200801233504.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据计算图计算z =（x+y)^2，z对x的偏导数：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200801233855.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单层的实现\n",
    "\n",
    "这里，我们把要实现的计算图的乘法节点称为“乘法层”（MulLayer），加法节点称为“加法层”（AddLayer）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乘法层的实现\n",
    "\n",
    "层的实现中有两个共通的方法（接口）forward()和backward()。forward()对应正向传播，backward()对应反向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乘法层的实现\n",
    "class MulLayer:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    # 反向传播——求导数\n",
    "    # dout--是一个系数（初始为1）\n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y\n",
    "        # print(f\"dx = {dout} * {self.y} = {dx}\")\n",
    "        dy = dout * self.x\n",
    "        # print(f\"dy = {dout} * {self.x} = {dy}\")\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新实现计算上面的苹果的问题：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200803112203.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "220.00000000000003\n"
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "# forward 前向传播\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)\n",
    "print(price) # 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.2 110.00000000000001 200\n"
    }
   ],
   "source": [
    "# backward\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "print(dapple, dapple_num, dtax) # 2.2 110 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加法层的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "\n",
    "    # 反向传播 加法的系数固定为1\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例子：购买两个苹果和三个橘子\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200803115844.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "总价为: 715.0000000000001\ndapple_num:110.00000000000001, \ndapple:2.2, \ndorange:3.3000000000000003, \ndorange_num:165.0, \ndtax:650\n"
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# forward\n",
    "# 买苹果\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num) #(1)\n",
    "# 买橘子\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num) #(2)\n",
    "# 价格相加\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price) #(3)\n",
    "# 加上税钱\n",
    "price = mul_tax_layer.forward(all_price, tax) #(4)\n",
    "\n",
    "\n",
    "# backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice) #(4)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) #(3)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price) #(2)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price) #(1)\n",
    "print(\"总价为:\", price) # 715\n",
    "print(f\"dapple_num:{dapple_num}, \\ndapple:{dapple}, \\ndorange:{dorange}, \\ndorange_num:{dorange_num}, \\ndtax:{dtax}\") # 110 2.2 3.3 165 650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现ReLu\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804163316.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量mask是由True/False构成的NumPy数组，它会把正向传播时的输入x的元素中小于等于0 的地方保存为True，其他地方（大于0 的元素）保存为False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 1.  -0.5]\n [-2.   3. ]]\n[[False  True]\n [ True False]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# mask 示例\n",
    "x = np.array( [[1.0, -0.5], [-2.0, 3.0]] )\n",
    "print(x)\n",
    "mask = (x <= 0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU 层的作用就像电路中的开关一样。\n",
    "\n",
    "正向传播时，有电流通过的话，就将开关设为ON；没有电流通过的话，就将开关设为OFF。反向传播时，开关为ON 的话，电流会直接通过；开关为OFF 的话，则不会有电流通过。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现Sigmoid\n",
    "\n",
    "函数表达式：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804170044.png)\n",
    "\n",
    "转换成计算图（仅正向传播）：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804170149.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmod计算图的反向传播\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804174559.png)\n",
    "\n",
    "对上述求导进行改写：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804174914.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简化后的计算图：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804175114.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仿射层\n",
    "\n",
    "神经网络的正向传播中进行的矩阵的乘积运算在几何学领域被称为“仿射变换”A。因此，这里将进行仿射变换的处理实现为“Affine层”。\n",
    "\n",
    "np.dot(X, W) + B的运算计算图可表示为：\n",
    "\n",
    "![计算图](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804180627.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播计算图\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804181129.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批版本的Affine 层\n",
    "\n",
    "前面介绍的Affine层的输入X是以单个数据为对象的。现在我们考虑N个数据一起进行正向传播的情况，也就是批版本的Affine层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804181437.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        \n",
    "        # 权重和偏置参数的导数\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 对应张量\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 还原输入数据的形状（对应张量）\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax-with-Loss层\n",
    "\n",
    "softmax 函数会将输入值正规化之后再输出。如在手写数字识别中：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804185908.png)\n",
    "\n",
    "输入图像通过Affine 层和ReLU层进行转换，10 个输入通过Softmax层进行正规化。在这个例子中，“0”的得分是5.3，这个值经过Softmax 层转换为0.008（0.8%）；“2”的得分是10.1，被转换为0.991（99.1%）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax-with-Loss 层（Softmax函数和交叉熵误差）的计算图如图：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804205722.png)\n",
    "\n",
    "简化版：\n",
    "\n",
    "![](https://gitee.com/liuyang0001/blogimage/raw/master/img/20200804211542.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None # softmax的输出\n",
    "        self.t = None # 监督数据\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 监督数据是one-hot-vector的情况\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络学习的全貌图\n",
    "\n",
    "前提:\n",
    "神经网络中有合适的权重和偏置，调整权重和偏置以便拟合训练数据的过程称为学习。神经网络的学习分为下面4个步骤:\n",
    "\n",
    "- 步骤1（mini-batch）\n",
    "从训练数据中随机选择一部分数据。\n",
    "- 步骤2（计算梯度）\n",
    "计算损失函数关于各个权重参数的梯度。\n",
    "- 步骤3（更新参数）\n",
    "将权重参数沿梯度方向进行微小的更新。\n",
    "- 步骤4（重复）\n",
    "\n",
    "重复步骤1、步骤2、步骤3。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}